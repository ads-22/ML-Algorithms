{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('./diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = diabetes.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = d[:,:-1]\n",
    "Y = d[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8) (768,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -1.  1. -1.  1. -1.  1. -1.  1.  1. -1.  1. -1.  1.  1.  1.  1.  1.\n",
      " -1.  1. -1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1.  1. -1. -1. -1. -1.\n",
      " -1.  1.  1.  1. -1. -1. -1.  1. -1.  1. -1. -1.  1. -1. -1. -1. -1.  1.\n",
      " -1. -1.  1. -1. -1. -1. -1.  1. -1. -1.  1. -1.  1. -1. -1. -1.  1. -1.\n",
      "  1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1. -1.\n",
      " -1. -1. -1.  1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1.  1.  1.  1. -1. -1.  1.  1.  1. -1. -1. -1.  1. -1. -1. -1.  1.  1.\n",
      " -1. -1.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1. -1. -1.  1. -1. -1.\n",
      " -1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1. -1. -1.  1. -1.  1. -1.  1.\n",
      " -1. -1. -1. -1. -1.  1.  1.  1.  1.  1. -1. -1.  1.  1. -1.  1. -1.  1.\n",
      "  1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1.  1. -1. -1. -1.  1.  1.  1.\n",
      "  1. -1.  1.  1.  1.  1. -1. -1. -1. -1. -1.  1. -1. -1.  1.  1. -1. -1.\n",
      " -1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1.  1.  1. -1. -1. -1.  1. -1.  1. -1. -1.  1. -1.  1. -1. -1.  1.\n",
      "  1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1. -1. -1.  1.  1. -1. -1.  1.\n",
      " -1. -1. -1.  1.  1.  1. -1. -1.  1. -1.  1. -1.  1.  1. -1.  1. -1. -1.\n",
      "  1. -1.  1.  1. -1. -1.  1. -1.  1. -1. -1.  1. -1.  1. -1.  1.  1.  1.\n",
      " -1. -1.  1. -1.  1. -1. -1. -1.  1. -1. -1. -1. -1.  1.  1.  1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1.  1.  1.  1. -1.  1.\n",
      "  1. -1. -1.  1. -1. -1.  1. -1. -1.  1.  1. -1. -1. -1. -1.  1. -1. -1.\n",
      "  1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1. -1. -1.  1. -1. -1.  1. -1.\n",
      " -1.  1. -1.  1.  1. -1.  1. -1.  1. -1.  1. -1.  1.  1. -1. -1. -1. -1.\n",
      "  1.  1. -1.  1. -1.  1. -1. -1. -1. -1.  1.  1. -1.  1. -1.  1. -1. -1.\n",
      " -1. -1. -1.  1. -1. -1. -1. -1.  1. -1. -1.  1.  1.  1. -1. -1.  1. -1.\n",
      " -1.  1. -1. -1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1. -1. -1. -1.  1.  1.\n",
      " -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1.  1. -1. -1. -1.  1. -1.\n",
      " -1. -1.  1. -1. -1. -1.  1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1.\n",
      " -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1.\n",
      "  1.  1.  1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.\n",
      " -1.  1. -1.  1.  1. -1. -1. -1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1.\n",
      " -1.  1. -1. -1.  1. -1. -1. -1. -1.  1.  1. -1.  1. -1. -1. -1. -1.  1.\n",
      "  1. -1.  1. -1. -1. -1.  1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1. -1.  1. -1. -1. -1.  1.  1.\n",
      "  1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1. -1.  1.  1.  1.  1. -1.\n",
      "  1.  1. -1. -1. -1. -1. -1. -1. -1.  1.  1. -1.  1. -1. -1.  1. -1.  1.\n",
      " -1. -1. -1. -1. -1.  1. -1.  1. -1.  1. -1.  1.  1. -1. -1. -1. -1.  1.\n",
      "  1. -1. -1. -1.  1. -1.  1.  1. -1. -1.  1. -1. -1.  1.  1. -1. -1.  1.\n",
      " -1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1. -1.\n",
      " -1.  1.  1. -1. -1.  1. -1. -1.  1. -1.  1.  1.  1. -1. -1.  1.  1.  1.\n",
      " -1.  1. -1.  1. -1.  1. -1. -1. -1. -1.  1. -1.]\n"
     ]
    }
   ],
   "source": [
    "Y[Y==0] =-1\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.reshape((-1,1))\n",
    "Y_test = Y_test.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 8) (154, 8)\n",
      "(614, 1) (154, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape)\n",
    "print(Y_train.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self,C=1.0):\n",
    "        self.C =C\n",
    "        # Weights\n",
    "        self.W =0\n",
    "        # bias\n",
    "        self.b =0\n",
    "    # Loss -->W,T\n",
    "    def hingeLoss(self,W,b,X,Y):\n",
    "        loss =0.0\n",
    "        loss+=0.5 *np.dot(W,W.T)\n",
    "        # Iterate over all examples\n",
    "        m = X.shape[0]\n",
    "        for i in range(m):\n",
    "            ti = Y[i] * (np.dot(W,X[i].T))\n",
    "            loss+= self.C * max(0,(1-ti))\n",
    "        return loss[0][0]\n",
    "    def fit(self,X,Y,batch_size=100,lr=0.001,max_itr=300):\n",
    "        no_of_features = X.shape[1]\n",
    "        no_of_samples = X.shape[0]\n",
    "        n = lr\n",
    "        C= self.C\n",
    "        \n",
    "        # initializing parameter\n",
    "        W = np.zeros((1,no_of_features))\n",
    "        bias = 0\n",
    "        print(self.hingeLoss(W,bias,X,Y))\n",
    "        \n",
    "        # Training\n",
    "        losses = []\n",
    "        for i in range(max_itr):\n",
    "            l = self.hingeLoss(W,bias,X,Y)\n",
    "            losses.append(l)\n",
    "            \n",
    "            ids = np.arange(no_of_samples)\n",
    "            np.random.shuffle(ids)\n",
    "            \n",
    "            # Batch Gradient\n",
    "            for batch_start in range(0,no_of_samples,batch_size):\n",
    "                # 0 gradient for batch\n",
    "                gradw =0\n",
    "                gradb =0\n",
    "                # Iterate over all examples in mini batch\n",
    "                for j in range(batch_size,batch_start+batch_size):\n",
    "                    if j<no_of_samples:\n",
    "                        i = ids[j]\n",
    "                        ti = Y[i] * (np.dot(W,X[i].T)+bias)\n",
    "                        if ti<1:\n",
    "                            gradw += C*Y[i]*X[i]\n",
    "                            gradb += C*Y[i]\n",
    "            W = W - n*W +n*gradw\n",
    "            bias = bias + n*gradb\n",
    "            \n",
    "        self.W = W\n",
    "        self.b = bias\n",
    "            \n",
    "        return W,bias,losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,W,b):\n",
    "        approx = np.dot(X,W.T) -b\n",
    "        return np.sign(approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614.0\n",
      "[[ 10.99138804  24.93406243 -33.77232228  -2.60097194   2.9121058\n",
      "   -7.55431766   0.29808421   4.66177496]]\n",
      "[-2.082]\n",
      "(1, 8) (768, 8)\n",
      "0.49348534201954397\n",
      "0.487012987012987\n"
     ]
    }
   ],
   "source": [
    "mySVM = SVM()\n",
    "W,b,losses = mySVM.fit(X_train,Y_train,max_itr=100)\n",
    "print(W)\n",
    "print(b)\n",
    "print(W.shape,X.shape)\n",
    "y1= predict(X_train,W,b)\n",
    "print(accuracy(y1,Y_train))\n",
    "y2 = predict(X_test,W,b)\n",
    "print(accuracy(y2,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614.0\n",
      "[[ 27.44665506  21.98771347 -36.27896611  -1.38969805   0.1385759\n",
      "   -8.05588412   0.81733378   6.92809433]]\n",
      "[-5.879]\n",
      "(1, 8) (768, 8)\n",
      "0.6156351791530945\n",
      "0.6038961038961039\n"
     ]
    }
   ],
   "source": [
    "mySVM = SVM()\n",
    "W,b,losses = mySVM.fit(X_train,Y_train,max_itr=300)\n",
    "print(W)\n",
    "print(b)\n",
    "print(W.shape,X.shape)\n",
    "y1= predict(X_train,W,b)\n",
    "print(accuracy(y1,Y_train))\n",
    "y2 = predict(X_test,W,b)\n",
    "print(accuracy(y2,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614.0\n",
      "[[ 37.03062764  -4.61364113 -51.03448169  -4.00007306 -20.53389855\n",
      "  -14.52353053   1.16951991   0.09701289]]\n",
      "[-9.976]\n",
      "(1, 8) (768, 8)\n",
      "0.6465798045602605\n",
      "0.6688311688311688\n"
     ]
    }
   ],
   "source": [
    "mySVM = SVM()\n",
    "W,b,losses = mySVM.fit(X_train,Y_train,max_itr=500)\n",
    "print(W)\n",
    "print(b)\n",
    "print(W.shape,X.shape)\n",
    "y1= predict(X_train,W,b)\n",
    "print(accuracy(y1,Y_train))\n",
    "y2 = predict(X_test,W,b)\n",
    "print(accuracy(y2,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429.79999999999546\n",
      "[[ 26.65784955  -5.19282463 -32.88657856  -1.75116195  -7.19553028\n",
      "   -9.68038622   0.75861114  -0.30626619]]\n",
      "[-6.9636]\n",
      "(1, 8) (768, 8)\n",
      "0.6465798045602605\n",
      "0.6688311688311688\n"
     ]
    }
   ],
   "source": [
    "mySVM = SVM(C=0.7)\n",
    "W,b,losses = mySVM.fit(X_train,Y_train,max_itr=500)\n",
    "print(W)\n",
    "print(b)\n",
    "print(W.shape,X.shape)\n",
    "y1= predict(X_train,W,b)\n",
    "print(accuracy(y1,Y_train))\n",
    "y2 = predict(X_test,W,b)\n",
    "print(accuracy(y2,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736.8000000000051\n",
      "[[ 45.72582554  31.69107407 -43.41833822   0.09200344   1.93902263\n",
      "   -7.68081396   1.47294429   8.81927864]]\n",
      "[-11.568]\n",
      "(1, 8) (768, 8)\n",
      "0.4609120521172638\n",
      "0.43506493506493504\n"
     ]
    }
   ],
   "source": [
    "mySVM = SVM(C=1.2)\n",
    "W,b,losses = mySVM.fit(X_train,Y_train,max_itr=500)\n",
    "print(W)\n",
    "print(b)\n",
    "print(W.shape,X.shape)\n",
    "y1= predict(X_train,W,b)\n",
    "print(accuracy(y1,Y_train))\n",
    "y2 = predict(X_test,W,b)\n",
    "print(accuracy(y2,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307.0\n",
      "[[ 19.19941573  10.71759945 -21.11747728  -0.63237674   1.30902188\n",
      "   -4.42825612   0.63403678   2.18238495]]\n",
      "[-4.8885]\n",
      "(1, 8) (768, 8)\n",
      "0.6498371335504886\n",
      "0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "mySVM = SVM(C=0.5)\n",
    "W,b,losses = mySVM.fit(X_train,Y_train,max_itr=500)\n",
    "print(W)\n",
    "print(b)\n",
    "print(W.shape,X.shape)\n",
    "y1= predict(X_train,W,b)\n",
    "print(accuracy(y1,Y_train))\n",
    "y2 = predict(X_test,W,b)\n",
    "print(accuracy(y2,Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
